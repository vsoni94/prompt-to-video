apiVersion: apps/v1
kind: Deployment
metadata:
  name: text2video-worker
spec:
  replicas: 1
  selector:
    matchLabels:
      app: text2video-worker
  template:
    metadata:
      labels:
        app: text2video-worker
    spec:
      runtimeClassName: nvidia                    # Use NVIDIA GPU runtime
      containers:
      - name: worker
        image: varunsoni94/text2video-api         # Same image, good
        command: ["/bin/bash", "-c", "/app/celery_worker.sh"]  # Entrypoint script
        volumeMounts:
        - name: output-volume
          mountPath: /mnt/data/output               # For output persistence
        - name: mochi-cache-volume                   # Mount model cache for worker too
          mountPath: /mnt/mochi-models
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: 96Gi                             # Set memory limits (adjust as needed)
            cpu: "16"                                # Set CPU limits (adjust as needed)
          requests:
            nvidia.com/gpu: 1
            memory: 64Gi
            cpu: "8"
      volumes:
      - name: output-volume
        hostPath:
          path: /mnt/data/output
          type: DirectoryOrCreate
      - name: mochi-cache-volume
        hostPath:
          path: /var/lib/mochi-models
          type: DirectoryOrCreate

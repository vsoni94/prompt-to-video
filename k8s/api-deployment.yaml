apiVersion: apps/v1
kind: Deployment
metadata:
  name: text2video-api
  labels:
    app: text2video-api
spec:
  replicas: 1
  selector:
    matchLabels:
      app: text2video-api
  template:
    metadata:
      labels:
        app: text2video-api
    spec:
      runtimeClassName: nvidia        # NVIDIA GPU runtime
      containers:
      - name: api
        image: varunsoni94/text2video-api  # Your image
        ports:
        - containerPort: 8000
        resources:
          limits:
            nvidia.com/gpu: 2            # Request 2 GPUs (adjust as needed)
            memory: 128Gi
            cpu: "32"
          requests:
            nvidia.com/gpu: 2
            memory: 192Gi
            cpu: "64"
        volumeMounts:
        - mountPath: /mnt/data/output
          name: output-volume
        - mountPath: /mnt/mochi-models          # Mount point for model cache
          name: mochi-cache-volume
      volumes:
      - name: output-volume
        hostPath:
          path: /mnt/data/output
          type: DirectoryOrCreate
      - name: mochi-cache-volume
        hostPath:
          path: /var/lib/mochi-models           # Host path to persist model weights
          type: DirectoryOrCreate

---
apiVersion: v1
kind: Service
metadata:
  name: text2video-api-service
spec:
  selector:
    app: text2video-api
  type: NodePort
  ports:
  - port: 8000
    targetPort: 8000
    nodePort: 30080   # Adjust as per your cluster's nodePort availability
